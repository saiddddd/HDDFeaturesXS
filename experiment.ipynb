{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement HDDFeaturesX==0.1.3 (from versions: 0.1.0, 0.1.1, 0.1.2)\n",
      "ERROR: No matching distribution found for HDDFeaturesX==0.1.3\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install HDDFeaturesX==0.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HDDFeaturesX import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 24\u001b[0m\n\u001b[0;32m     20\u001b[0m data \u001b[38;5;241m=\u001b[39m data_loaded[data_key]\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Partition data into two parts\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m parts \u001b[38;5;241m=\u001b[39m \u001b[43mpartition_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m ori_data \u001b[38;5;241m=\u001b[39m parts[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     26\u001b[0m A \u001b[38;5;241m=\u001b[39m parts[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\for_sharing\\for_sharing\\HDDFeaturesX\\HDDFeaturesX\\partition_fold.py:88\u001b[0m, in \u001b[0;36mpartition_fold\u001b[1;34m(data, k, max_iterations)\u001b[0m\n\u001b[0;32m     86\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     87\u001b[0m num_agents \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m  \u001b[38;5;66;03m# You can adjust this based on the problem size\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m optimal_indices \u001b[38;5;241m=\u001b[39m \u001b[43mgwo_optimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_agents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iterations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m optimal_indices \u001b[38;5;241m=\u001b[39m optimal_indices\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Partition the data using the optimized indices\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\for_sharing\\for_sharing\\HDDFeaturesX\\HDDFeaturesX\\partition_fold.py:76\u001b[0m, in \u001b[0;36mpartition_fold.<locals>.gwo_optimize\u001b[1;34m(dim, n_agents, max_iterations)\u001b[0m\n\u001b[0;32m     73\u001b[0m X3 \u001b[38;5;241m=\u001b[39m delta_pos[j] \u001b[38;5;241m-\u001b[39m A3 \u001b[38;5;241m*\u001b[39m D_delta\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Weights based on long-tail distribution (alpha > beta > delta)\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpareto\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m)  \n\u001b[0;32m     77\u001b[0m weights \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(weights) \n\u001b[0;32m     80\u001b[0m new_position \u001b[38;5;241m=\u001b[39m weights[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m X1 \u001b[38;5;241m+\u001b[39m weights[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m X2 \u001b[38;5;241m+\u001b[39m weights[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m*\u001b[39m X3\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# csv file\n",
    "# data_path = 'Brain1.csv'\n",
    "# data = pd.read_csv(data_path)\n",
    "# data = np.array(data)\n",
    "\n",
    "# mat file\n",
    "# Load data\n",
    "data_path = 'PCMAC.mat'\n",
    "data_loaded = loadmat(data_path)\n",
    "data_key = next(key for key in data_loaded.keys() if not key.startswith('__'))\n",
    "data = data_loaded[data_key]\n",
    "\n",
    "\n",
    "# Partition data into two parts\n",
    "parts = partition_fold(data, 2)\n",
    "ori_data = parts[0]\n",
    "A = parts[1]\n",
    "\n",
    "# Further split part A into 5\n",
    "U = partition_fold(A, 5)\n",
    "\n",
    "start_time = time.time()\n",
    "# Initial feature selection on original data\n",
    "fea_slt, ds_vector, fea_redun, sam_delete, ori_time = fast_feature_selection_ds(ori_data)\n",
    "\n",
    "# Incrementally update feature selection as new data becomes available\n",
    "add_data = np.array([])\n",
    "in_fea_slt_fs = []\n",
    "unuse_ds = []\n",
    "nrf_fs = []\n",
    "nrs_fs = []\n",
    "time_in_ds_fs = np.array([])\n",
    "\n",
    "for i in range(5):\n",
    "    add_data = np.vstack([add_data, U[i]]) if add_data.size else U[i]\n",
    "    result = incre_fea_slt_ds_filter_sam(ori_data, add_data, ds_vector, fea_slt)\n",
    "    in_fea_slt_fs.append(result[0])\n",
    "    unuse_ds.append(result[1])\n",
    "    nrf_fs.append(result[2])\n",
    "    nrs_fs.append(result[3])\n",
    "    time_in_ds_fs = np.append(time_in_ds_fs, result[4])\n",
    "\n",
    "\n",
    "# Calculate total execution time\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Use selected features for training and testing\n",
    "X_selected = ori_data[:, fea_slt]\n",
    "y = ori_data[:, -1]\n",
    "y = y.astype(int)\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train KNN model\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict classes for test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Save time_in_ds_fs\n",
    "results_path = 'timeInDSfs.txt'\n",
    "np.savetxt(results_path, time_in_ds_fs, delimiter=',')\n",
    "\n",
    "# Print total execution time\n",
    "print(f\"Total execution time: {total_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2270,\n",
       " 990,\n",
       " 2936,\n",
       " 945,\n",
       " 506,\n",
       " 1393,\n",
       " 2892,\n",
       " 247,\n",
       " 1809,\n",
       " 2033,\n",
       " 3258,\n",
       " 2303,\n",
       " 1794,\n",
       " 3015,\n",
       " 1787,\n",
       " 1552,\n",
       " 1966,\n",
       " 2866,\n",
       " 2546,\n",
       " 170,\n",
       " 1014]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_slt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
